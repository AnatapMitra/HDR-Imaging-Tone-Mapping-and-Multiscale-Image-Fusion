# -*- coding: utf-8 -*-
"""DIP_Project(code).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A4JeTJ5OduLt57541y8UeC1LuEBo8XNa

## ***Exponential Tone Mapping***
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

def exponential_tone_mapping(hdr_image, a=1.2):

    # Convert HDR image to float32 in range [0, 1]
    hdr_image = hdr_image.astype(np.float32) / 255.0

    # Calculate luminance (Y)
    luminance = 0.299 * hdr_image[..., 2] + 0.587 * hdr_image[..., 1] + 0.114 * hdr_image[..., 0]
    L_av = np.mean(luminance)

    # Apply exponential tone mapping to luminance
    L_d = 1 - np.exp(-luminance * a / L_av)

    # Calculate chrominance
    C_r = hdr_image[..., 2] / (luminance + 1e-6)  # Avoid division by zero
    C_g = hdr_image[..., 1] / (luminance + 1e-6)
    C_b = hdr_image[..., 0] / (luminance + 1e-6)

    # Reconstruct RGB channels using tone-mapped luminance
    R_LDR = L_d * C_r
    G_LDR = L_d * C_g
    B_LDR = L_d * C_b

    # Combine channels and clip to [0, 255]
    ldr_image = np.stack((B_LDR, G_LDR, R_LDR), axis=-1)
    ldr_image = np.clip(ldr_image * 255, 0, 255).astype(np.uint8)

    return ldr_image, L_d, luminance  # Return L_d and luminance for plotting

hdr_image_list = ['mpi_office', 'nancy_church_1']
a_values = [0.8, 1.0, 1.5]  # Three different 'a' values for comparison

# Loop over each HDR image
for image in hdr_image_list:
    hdr_image = cv2.imread('/content/drive/MyDrive/DIP final project/HDR/Images/' + image + '.hdr', cv2.IMREAD_ANYDEPTH)

    # Create a figure with subplots to show the images side by side
    plt.figure(figsize=(15, 5))
    plt.suptitle(f'LDR Images of {image} (Exponential Tone Mapped)', fontsize=16)

    # Loop over the different 'a' values and plot the results side by side
    for idx, a in enumerate(a_values):
        # Apply exponential tone mapping with the current 'a' value
        ldr_image, L_d, luminance = exponential_tone_mapping(hdr_image, a)

        # Plot the resulting LDR image
        plt.subplot(1, 3, idx + 1)  # 1 row, 3 columns, plot at the (idx+1)-th position
        plt.imshow(cv2.cvtColor(ldr_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display
        plt.title(f'a = {a}')
        plt.axis('off')


    # Display the images
    plt.show()

"""## ***Reinhard Global Mapping***"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

def reinhard_global_tone_mapping(hdr_image, a=0.18):
    # Convert HDR image to float32 in range [0, 1]
    hdr_image = hdr_image.astype(np.float32) / 255.0

    # Calculate luminance (Y) and average luminance (L_av)
    luminance = 0.299 * hdr_image[..., 2] + 0.587 * hdr_image[..., 1] + 0.114 * hdr_image[..., 0]

    # Calculate the log average luminance value
    L_log_av = np.exp(np.mean(np.log(luminance + 1e-6)))

    # Determine L_white as the maximum luminance in the HDR image
    L_white = np.max(luminance)

    # Step 4: Scale the luminance map based on the average luminance and the key value 'a'
    L_m = (a / L_log_av) * luminance

    # Step 5: Apply tone mapping with L_white to compress high luminance values
    luminance_tone_mapped = (L_m * (1 + (L_m / (L_white ** 2)))) / (1 + L_m)

    # Calculate chrominance
    C_r = hdr_image[..., 2] / (luminance + 1e-6)  # Avoid division by zero
    C_g = hdr_image[..., 1] / (luminance + 1e-6)
    C_b = hdr_image[..., 0] / (luminance + 1e-6)

    # Reconstruct RGB channels using tone-mapped luminance
    R_LDR = luminance_tone_mapped * C_r
    G_LDR = luminance_tone_mapped * C_g
    B_LDR = luminance_tone_mapped * C_b

    # Combine channels and clip to [0, 255]
    ldr_image = np.stack((B_LDR, G_LDR, R_LDR), axis=-1)
    ldr_image = np.clip(ldr_image * 255, 0, 255).astype(np.uint8)

    return ldr_image

hdr_image_list = ['mpi_office', 'nancy_church_1']
a_values = [0.18, 0.5, 1.0]  # Three different 'a' values

# Loop over each HDR image
for image in hdr_image_list:
    hdr_image = cv2.imread('/content/drive/MyDrive/DIP final project/HDR/Images/' + image + '.hdr', cv2.IMREAD_ANYDEPTH)

    # Create a figure with subplots to show the images side by side
    plt.figure(figsize=(15, 5))
    plt.suptitle(f'LDR Images of {image} (Reinhard Global Tone Mapped)', fontsize=16)

    # Loop over the different 'a' values and plot the results side by side
    for idx, a in enumerate(a_values):
        # Apply Reinhard global tone mapping with the current 'a' value
        ldr_image = reinhard_global_tone_mapping(hdr_image, a)

        # Plot the resulting LDR image
        plt.subplot(1, 3, idx + 1)  # 1 row, 3 columns, plot at the (idx+1)-th position
        plt.imshow(cv2.cvtColor(ldr_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display
        plt.title(f'a = {a}')
        plt.axis('off')

    # Display the images
    plt.show()

"""## ***Reinhard Local Mapping***"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def reinhard_local_tone_mapping(hdr_image, key=0.18, eps=1e-6):

    # Convert the image to grayscale to obtain luminance
    luminance = cv2.cvtColor(hdr_image, cv2.COLOR_BGR2GRAY)

    # Compute the log average luminance
    log_avg_luminance = np.exp(np.mean(np.log(luminance + eps)))

    # Scale the luminance by the key and the log average luminance
    scaled_luminance = (key / log_avg_luminance) * luminance

    # Apply local tone mapping using a Gaussian filter
    local_luminance = cv2.GaussianBlur(scaled_luminance, (0, 0), sigmaX=2, sigmaY=2)

    # Compute the tone-mapped luminance
    tone_mapped_luminance = scaled_luminance / (1 + local_luminance)

    # Reintroduce color by scaling the original HDR image by the tone-mapped luminance
    color_scale = tone_mapped_luminance / (luminance + eps)
    tone_mapped_image = hdr_image * color_scale[..., np.newaxis]

    # Clip values to the [0, 1] range and convert to 8-bit LDR format
    tone_mapped_image = np.clip(tone_mapped_image, 0, 1)
    ldr_image = (tone_mapped_image * 255).astype(np.uint8)

    return ldr_image

hdr_image_list = ['mpi_office', 'nancy_church_1']
a_values = [0.18, 0.5, 1.0]  # Three different 'a' values

# Loop over each HDR image and each 'a' value
for image in hdr_image_list:
    hdr_image = cv2.imread('/content/drive/MyDrive/DIP final project/HDR/Images/'+image+'.hdr', cv2.IMREAD_ANYDEPTH)

    # Create a figure with subplots for side-by-side display
    plt.figure(figsize=(15, 5))
    plt.suptitle(f'LDR Image of {image} (Reinhard Local Tone Mapped)')

    # Loop over the different 'a' values and show the results side by side
    for idx, a in enumerate(a_values):
        # Apply Reinhard local tone mapping with the current 'a' value
        ldr_image = reinhard_local_tone_mapping(hdr_image, key=a)

        # Plot the resulting LDR image
        plt.subplot(1, 3, idx + 1)  # 1 row, 3 columns, plot at the (idx+1)-th position
        plt.imshow(cv2.cvtColor(ldr_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display
        plt.title(f'a = {a}')
        plt.axis('off')

    # Display the images
    plt.show()

"""# Metric Computation"""

import numpy as np
import cv2
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

# Define the tone-mapping function
def reinhard_global_tone_mapping(hdr_image,a=0.18):
    # Convert HDR image to float32 in range [0, 1]
    hdr_image = hdr_image.astype(np.float32) /255.0

    # Calculate luminance (Y) and average luminance (L_av)
    luminance = 0.299 * hdr_image[..., 2] + 0.587 * hdr_image[..., 1] + 0.114 * hdr_image[..., 0]

    # Calculate the log average luminance value
    L_log_av = np.exp(np.mean(np.log(luminance + 1e-6)))
    #normalize the luminance values
    #Determine L_white as the maximum luminance in the HDR image
    L_white = np.max(luminance)
    #print(L_white)

    # Step 4: Scale the luminance map based on the average luminance and the key value 'a'
    L_m = (a / L_log_av) * luminance

    # Step 5: Apply tone mapping with L_white to compress high luminance values
    luminance_tone_mapped= (L_m * (1 + (L_m / (L_white ** 2)))) / (1 + L_m)


    # Calculate chrominance
    C_r = hdr_image[..., 2] / (luminance + 1e-6)  # Avoid division by zero
    C_g = hdr_image[..., 1] / (luminance + 1e-6)
    C_b = hdr_image[..., 0] / (luminance + 1e-6)

    # Reconstruct RGB channels using tone-mapped luminance
    R_LDR = luminance_tone_mapped * C_r
    G_LDR = luminance_tone_mapped * C_g
    B_LDR = luminance_tone_mapped * C_b

    # Combine channels and clip to [0, 255]
    ldr_image = np.stack((B_LDR, G_LDR, R_LDR), axis=-1)
    ldr_image = np.clip(ldr_image * 255, 0, 255).astype(np.uint8)

    return ldr_image






def colorfulness(image):
    rg = image[..., 0] - image[..., 1]
    yb = 0.5 * (image[..., 0] + image[..., 1]) - image[..., 2]
    std_rg = np.std(rg)
    std_yb = np.std(yb)
    mean_rg = np.mean(rg)
    mean_yb = np.mean(yb)
    colorfulness_score = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)
    return colorfulness_score



# Compute MSSIM for color images
def compute_mssim(reference_image, comparison_image):
    # Compute MSSIM for each channel (R, G, B) and then average
    mssim_values = []
    for i in range(3):
        mssim_value = ssim(reference_image[..., i], comparison_image[..., i], data_range=reference_image[..., i].max() - reference_image[..., i].min())
        mssim_values.append(mssim_value)
    return np.mean(mssim_values)

# Compute TMQI for color images
def structural_fidelity(hdr_image, ldr_image):
    # Compute SSIM as a proxy for structural fidelity for each channel
    ssim_values = []
    for i in range(3):
        ssim_value = ssim(hdr_image[..., i], ldr_image[..., i], data_range=ldr_image[..., i].max() - ldr_image[..., i].min())
        ssim_values.append(ssim_value)
    return np.mean(ssim_values)




# Define HDR image file list
hdr_image_list = ['mpi_office',  'nancy_church_1']

# Initialize lists to store metric values
colorfulness_values = []

mssim_values = []


# Load HDR images and apply tone mapping
for image_name in hdr_image_list:
    # Load HDR image
    hdr_image = cv2.imread(f'/content/drive/MyDrive/DIP final project/HDR/Images/{image_name}.hdr', cv2.IMREAD_ANYDEPTH)

    # Apply exponential tone mapping
    ldr_image = reinhard_global_tone_mapping(hdr_image)

    # Calculate metrics for HDR and LDR

    colorfulness_score = colorfulness(ldr_image)

    mssim_value = compute_mssim(hdr_image, ldr_image)


    # Append metric values to lists

    colorfulness_values.append(colorfulness_score)

    mssim_values.append(mssim_value)


    # Plot HDR image and its tone-mapped version
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.title(f'HDR Image: {image_name}')
    plt.imshow(np.clip(hdr_image, 0, 255))# Display HDR image in grayscale
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title(f'Tone Mapped Image: {image_name} (exponential_tone_mapped)')
    plt.imshow(cv2.cvtColor(ldr_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display
    plt.axis('off')

    plt.show()

# Calculate and display mean and standard deviation of each metric
print("Colorfulness (C) - Mean:", np.mean(colorfulness_values), "Std Dev:", np.std(colorfulness_values))

print("MSSIM - Mean:", np.mean(mssim_values), "Std Dev:", np.std(mssim_values))

# Data for MSSIM
exponential_mssim = 0.8753664475031925

reinhard_global_mssim = 0.8946434992053616
reinhard_local_mssim = 0.8957735609797519

# MSSIM values
mssim_values = [exponential_mssim,  reinhard_global_mssim, reinhard_local_mssim]

# Bar chart for MSSIM
plt.figure(figsize=(4, 3))
plt.bar(labels, mssim_values, color=['b',  'r', 'c'])
plt.title('MSSIM')
plt.xlabel('Tone Mappers')
plt.ylabel('Value')
plt.tight_layout()
plt.show()

# Data for Colorfulness (C)
exponential_c = 159.79476646286292

reinhard_global_c = 150.4352062031184
reinhard_local_c = 150.258985581649

# Colorfulness values
c_values = [exponential_c ,reinhard_global_c, reinhard_local_c]

# Bar chart for Colorfulness (C)
plt.figure(figsize=(4, 3))
plt.bar(labels, c_values, color=['b', 'r', 'c'])
plt.title('Colorfulness (C)')
plt.xlabel('Tone Mappers')
plt.ylabel('Value')
plt.tight_layout()
plt.show()

"""# ***Gaussian/Laplacian based MEF***"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

# Helper function to visualize weight maps
#def visualize_weight_maps(weight_maps):



def resize_images(original_images):
    resized_images = []
    for image in original_images:
        img = cv2.resize(image, (256, 200))
        resized_images.append(img / 255.0)  # Normalize to [0, 1]
    return resized_images
# Gaussian convolution
def convolve_gaussian(image, kernel_size, std_dev):
    gaussian_kernel = cv2.getGaussianKernel(kernel_size, std_dev)
    gaussian_kernel = gaussian_kernel * gaussian_kernel.T
    return cv2.filter2D(image, -1, gaussian_kernel)

# Laplacian convolution
def convolve_laplacian(image):
    laplacian_kernel = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])
    return cv2.filter2D(image, -1, laplacian_kernel)

# Contrast, saturation, and well-exposedness maps
def contrast_map(image):
    return np.abs(convolve_laplacian(image))

def saturation_map(image):
    image_uint8 = (image * 255).astype(np.uint8)
    hsv_image = cv2.cvtColor(image_uint8, cv2.COLOR_BGR2HSV)
    return hsv_image[:, :, 1] / 255.0

def well_exposedness_map(image):
    mid_intensity = 0.5
    sigma = 1.5
    return np.exp(-((image - mid_intensity) ** 2) / (2 * sigma ** 2))

# Weight maps
def weight_map(original_image_list):
    weight_map_list = []
    for image in original_image_list:
        contrast = contrast_map(image)
        saturation = saturation_map(image)
        well_exposedness = well_exposedness_map(image)

        combined_weight = contrast * saturation[..., np.newaxis] * well_exposedness
        weight_map_list.append(combined_weight)

    weight_map_array = np.array(weight_map_list)

    # Ensure no division by zero by adding a small constant where the sum is zero
    sum_weights = np.sum(weight_map_array, axis=0, keepdims=True)
    sum_weights[sum_weights == 0] = 1e-6  # Avoid division by zero

    normalized_weight_map_list = weight_map_array / sum_weights

    # Visualize normalized weight maps
    #visualize_weight_maps([np.sum(w, axis=2) for w in normalized_weight_map_list])

    return normalized_weight_map_list

# Gaussian and Laplacian pyramids using OpenCV pyrDown and pyrUp
def gaussian_pyramid(weight_map_list, l):
    gaussian_sequence_list = []
    for image in weight_map_list:
        gaussian_sequence = [image]
        for i in range(1, l):
            image = cv2.pyrDown(image)
            gaussian_sequence.append(image)
        gaussian_sequence_list.append(gaussian_sequence)
    return gaussian_sequence_list

def laplacian_pyramid(original_image_list, l):
    laplacian_sequence_list = []
    for image in original_image_list:
        gaussian_sequence = [image]
        for i in range(1, l):
            image = cv2.pyrDown(image)
            gaussian_sequence.append(image)

        laplacian_sequence = []
        for j in range(l - 1):
            expanded = cv2.pyrUp(gaussian_sequence[j + 1], dstsize=(gaussian_sequence[j].shape[1], gaussian_sequence[j].shape[0]))
            laplacian = cv2.subtract(gaussian_sequence[j], expanded)
            laplacian_sequence.append(laplacian)
        laplacian_sequence.append(gaussian_sequence[-1])  # Last level
        laplacian_sequence_list.append(laplacian_sequence)
    return laplacian_sequence_list

# Pointwise multiplication of Gaussian and Laplacian sequences
def pointwise_multiplication(gaussian_sequence_list, laplacian_sequence_list):
    result_list = []
    for i in range(len(gaussian_sequence_list)):
        multiplied_sequence = []
        for j in range(len(gaussian_sequence_list[i])):
            multiplied_matrix = gaussian_sequence_list[i][j] * laplacian_sequence_list[i][j]
            multiplied_sequence.append(multiplied_matrix)
        result_list.append(multiplied_sequence)
    return result_list

# Fused Laplacian map
def fused_laplacian_map(return_list):
    fused_laplacian_map_list = []
    for j in range(len(return_list[0])):
        sum_map = np.zeros_like(return_list[0][j], dtype=np.float32)
        for i in range(len(return_list)):
            sum_map += return_list[i][j]
        fused_laplacian_map_list.append(sum_map)
    return fused_laplacian_map_list

# Fused image from Laplacian maps
def fused_image(fused_laplacian_map_list):
    fused_img = fused_laplacian_map_list[-1]
    for i in range(len(fused_laplacian_map_list) - 2, -1, -1):
        fused_img = cv2.pyrUp(fused_img, dstsize=(fused_laplacian_map_list[i].shape[1], fused_laplacian_map_list[i].shape[0]))
        fused_img = cv2.add(fused_img, fused_laplacian_map_list[i])

    # Clip values before converting to uint8
    fused_img = np.clip(fused_img, 0, 1)
    return fused_img



# Display function with resizing for visualization
def display(original_image_list, fused_image):
    plt.figure(figsize=(20, 10))
    for i in range(len(original_image_list)):
        # Resize the original images to 256x480 for display
        #display_img = cv2.resize(original_image_list[i], (480, 256))
        display_img = (original_image_list[i] * 255).astype(np.uint8)
        plt.subplot(1, len(original_image_list) + 1, i + 1)
        plt.imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))
        plt.title(f'Original Image {i + 1}')
        plt.axis('off')

    # Resize the fused image to 256x480 for display
    #fused_image_resized = cv2.resize(fused_image, (480, 256))
    fused_image_uint8 = (fused_image * 255).astype(np.uint8)
    plt.subplot(1, len(original_image_list) + 1, len(original_image_list) + 1)
    plt.imshow(cv2.cvtColor(fused_image_uint8, cv2.COLOR_BGR2RGB))
    plt.title('Fused Image')
    plt.axis('off')
    plt.show()




# Load and preprocess images
image_paths = [
    '/content/drive/MyDrive/DIP final project/HDR/Images/image_set_2.1.png',

    '/content/drive/MyDrive/DIP final project/HDR/Images/image_set_2.2.png'
]
original_image_list = [cv2.imread(path) for path in image_paths]










# Perform multi-exposure fusion

# Process (one by one function calls that I have written )


original_image_list = resize_images(original_image_list)
weight_map_list = weight_map(original_image_list)
gaussian_sequence_list = gaussian_pyramid(weight_map_list, 4)
laplacian_sequence_list = laplacian_pyramid(original_image_list, 4)
return_list = pointwise_multiplication(gaussian_sequence_list, laplacian_sequence_list)
fused_laplacian_map_list = fused_laplacian_map(return_list)
fused_img = fused_image(fused_laplacian_map_list)



# Display results
display(original_image_list, fused_img)

#functions integrated with the previous code for computing some metrics

import numpy as np
import cv2
import matplotlib.pyplot as plt


#Visualize weight maps
def visualize_weight_maps(weight_maps):
    plt.figure(figsize=(12, 4))
    for i, weight_map in enumerate(weight_maps):
        plt.subplot(1, len(weight_maps), i + 1)
        plt.imshow(weight_map, cmap='gray')
        plt.title(f'Weight Map {i + 1}')
        plt.axis('off')
    plt.show()

# Ensure all input images have the same dimensions
def resize_images(original_images):
    resized_images = []
    for image in original_images:
        img = cv2.resize(image, (256, 200))
        resized_images.append(img / 255.0)  # Normalize to [0, 1]
    return resized_images

# Gaussian convolution
def convolve_gaussian(image, kernel_size, std_dev):
    gaussian_kernel = cv2.getGaussianKernel(kernel_size, std_dev)
    gaussian_kernel = gaussian_kernel * gaussian_kernel.T
    return cv2.filter2D(image, -1, gaussian_kernel)

# Laplacian convolution
def convolve_laplacian(image):
    laplacian_kernel = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])
    return cv2.filter2D(image, -1, laplacian_kernel)

# Contrast, saturation, and well-exposedness maps
def contrast_map(image):
    return np.abs(convolve_laplacian(image))

def saturation_map(image):
    image_uint8 = (image * 255).astype(np.uint8)
    hsv_image = cv2.cvtColor(image_uint8, cv2.COLOR_BGR2HSV)
    return hsv_image[:, :, 1] / 255.0

def well_exposedness_map(image):
    mid_intensity = 0.5
    sigma = 1.5
    return np.exp(-((image - mid_intensity) ** 2) / (2 * sigma ** 2))

# Weight maps computation
def weight_map(original_image_list):
    weight_map_list = []
    for image in original_image_list:
        contrast = contrast_map(image)
        saturation = saturation_map(image)
        well_exposedness = well_exposedness_map(image)

        combined_weight = contrast * saturation[..., np.newaxis] * well_exposedness #expanding saturation map in 3 color channels
        weight_map_list.append(combined_weight)

    weight_map_array = np.array(weight_map_list)
    sum_weights = np.sum(weight_map_array, axis=0, keepdims=True)
    sum_weights[sum_weights == 0] = 1e-6  # Avoid division by zero
    normalized_weight_map_list = weight_map_array / sum_weights

    # Visualize normalized weight maps
    visualize_weight_maps([np.sum(w, axis=2) for w in normalized_weight_map_list])

    return normalized_weight_map_list

# Gaussian and Laplacian pyramids
def gaussian_pyramid(weight_map_list, l):
    gaussian_sequence_list = []
    for image in weight_map_list:
        gaussian_sequence = [image]
        for i in range(1, l):
            image = cv2.pyrDown(image) #computing gaussian and downsampling
            gaussian_sequence.append(image)
        gaussian_sequence_list.append(gaussian_sequence)
    return gaussian_sequence_list

def laplacian_pyramid(original_image_list, l):
    laplacian_sequence_list = []
    for image in original_image_list:
        gaussian_sequence = [image]
        for i in range(1, l):
            image = cv2.pyrDown(image)
            gaussian_sequence.append(image)

        laplacian_sequence = []
        for j in range(l - 1):
            expanded = cv2.pyrUp(gaussian_sequence[j + 1], dstsize=(gaussian_sequence[j].shape[1], gaussian_sequence[j].shape[0])) #computing gausian and upscaling
            laplacian = cv2.subtract(gaussian_sequence[j], expanded)
            laplacian_sequence.append(laplacian)
        laplacian_sequence.append(gaussian_sequence[-1])  # Last level
        laplacian_sequence_list.append(laplacian_sequence)
    return laplacian_sequence_list

# Pointwise multiplication of Gaussian and Laplacian sequences
def pointwise_multiplication(gaussian_sequence_list, laplacian_sequence_list):
    result_list = []
    for i in range(len(gaussian_sequence_list)):
        multiplied_sequence = []
        for j in range(len(gaussian_sequence_list[i])):
            multiplied_matrix = gaussian_sequence_list[i][j] * laplacian_sequence_list[i][j]
            multiplied_sequence.append(multiplied_matrix)
        result_list.append(multiplied_sequence)
    return result_list

# Fused Laplacian map
def fused_laplacian_map(return_list):
    fused_laplacian_map_list = []
    for j in range(len(return_list[0])):
        sum_map = np.zeros_like(return_list[0][j], dtype=np.float32)
        for i in range(len(return_list)):
            sum_map += return_list[i][j]
        fused_laplacian_map_list.append(sum_map)
    return fused_laplacian_map_list

# Fused image from Laplacian maps
def fused_image(fused_laplacian_map_list):
    fused_img = fused_laplacian_map_list[-1]
    for i in range(len(fused_laplacian_map_list) - 2, -1, -1):
        fused_img = cv2.pyrUp(fused_img, dstsize=(fused_laplacian_map_list[i].shape[1], fused_laplacian_map_list[i].shape[0]))
        fused_img = cv2.add(fused_img, fused_laplacian_map_list[i])

    # Clipping values before converting to uint8
    fused_img = np.clip(fused_img, 0, 1)
    return fused_img

# Display function for visualization
def display(original_image_list, fused_image):
    plt.figure(figsize=(20, 10))
    for i in range(len(original_image_list)):
        display_img = (original_image_list[i] * 255).astype(np.uint8)
        plt.subplot(1, len(original_image_list) + 1, i + 1)
        plt.imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))
        plt.title(f'Original Image {i + 1}')
        plt.axis('off')

    fused_image_uint8 = (fused_image * 255).astype(np.uint8)
    plt.subplot(1, len(original_image_list) + 1, len(original_image_list) + 1)
    plt.imshow(cv2.cvtColor(fused_image_uint8, cv2.COLOR_BGR2RGB))
    plt.title('Fused Image')
    plt.axis('off')
    plt.show()


# Metric computation functions

# MS-SSIM computation
from skimage.metrics import structural_similarity as ssim

def compute_msssim(fused_img, ref_img):
    return ssim(fused_img, ref_img, data_range=255, win_size=3, channel_axis=-1)

# MSE computation
def compute_mse(fused_img, ref_img):
    return np.mean((fused_img - ref_img) ** 2)  # Operates across all channels

# PSNR computation
def compute_psnr(fused_img, ref_img):
    mse = compute_mse(fused_img, ref_img)
    if mse == 0:
        return float('inf')
    return 20 * np.log10(255.0 / np.sqrt(mse))

# Entropy computation (average over color channels)
def compute_entropy(fused_img):
    # Normalize image to [0, 1]
    fused_img = fused_img / 255.0

    # Compute the histogram of the image
    hist, _ = np.histogram(fused_img.ravel(), bins=256, range=(0, 1), density=True)

    # Remove zero probabilities to avoid log(0)
    hist = hist[hist > 0]

    # Ensure the histogram sums to 1 (probability distribution)
    hist /= np.sum(hist)

    # Compute entropy
    if hist.size > 0:  # Ensure there's valid data in hist
        entropy = -np.sum(hist * np.log2(hist))
        return entropy
    else:
        return 0.0  # Return 0 if no valid data exists





# FQI computation (operates on flattened arrays of all channels)
def compute_fqi(fused_img, ref_img):
    fused_flat = fused_img.flatten()
    ref_flat = ref_img.flatten()
    return np.corrcoef(fused_flat, ref_flat)[0, 1]


# Load and preprocess images
image_paths = [
    '/content/drive/MyDrive/DIP final project/HDR/Images/image_set_2.1.png',
    '/content/drive/MyDrive/DIP final project/HDR/Images/image_set_2.2.png',
    #'/content/drive/MyDrive/DIP final project/HDR/Images/image_set_1.3.png'
]
original_image_list = [cv2.imread(path) for path in image_paths]



# Resize and process images
original_image_list = resize_images(original_image_list)
ref_image = np.mean(original_image_list, axis=0) * 255  # Simple average of all input images , scale to [0, 255]

# Fusion process calling functions one by one
weight_map_list = weight_map(original_image_list)
gaussian_sequence_list = gaussian_pyramid(weight_map_list, 4)
laplacian_sequence_list = laplacian_pyramid(original_image_list, 4)
return_list = pointwise_multiplication(gaussian_sequence_list, laplacian_sequence_list)
fused_laplacian_map_list = fused_laplacian_map(return_list)
fused_img = fused_image(fused_laplacian_map_list)

# Scale fused image to [0, 255]
fused_img_uint8 = (fused_img * 255).astype(np.uint8)
ref_image_uint8 = ref_image.astype(np.uint8)

#convert fused image into grayscale


# Evaluation

fused_img_gray = cv2.cvtColor((fused_img * 255).astype(np.uint8), cv2.COLOR_BGR2GRAY) / 255.0

# Metric calculations
msssim_value = compute_msssim(fused_img_uint8, ref_image_uint8)
mse_value = compute_mse(fused_img_uint8, ref_image_uint8)
psnr_value = compute_psnr(fused_img_uint8, ref_image_uint8)
entropy_value = compute_entropy(fused_img_gray*255)
fqi_value = compute_fqi(fused_img_uint8, ref_image_uint8)

# Display the metrics
print('computed metrics')
print(f"MS-SSIM: {msssim_value:.4f}")
print(f"MSE: {mse_value:.4f}")
print(f"PSNR: {psnr_value:.4f} dB")
print(f"Entropy: {entropy_value:.4f}")
print(f"FQI: {fqi_value:.4f}")


# Display results
display(original_image_list, fused_img)

from google.colab import drive
drive.mount('/content/drive')